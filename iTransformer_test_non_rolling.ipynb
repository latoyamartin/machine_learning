{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9FqX4hD4J9t"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/Nixtla/neuralforecast.git"
      ],
      "metadata": {
        "id": "cBAvViNl63Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "import copy\n",
        "from datetime import datetime\n",
        "from neuralforecast.core import NeuralForecast\n",
        "from neuralforecast.models import NHITS, PatchTST, iTransformer, TSMixer\n",
        "from utilsforecast.losses import mae, mse\n",
        "from utilsforecast.evaluation import evaluate\n",
        "\n",
        "\n",
        "def load_stock_data(ticker, start_date, end_date):\n",
        "    data = yf.download(ticker, start=start_date, end=end_date)\n",
        "    data = data[['Close', 'Volume']]  # Include trading volume as a feature\n",
        "    data['Returns'] = data['Close'].pct_change()  # Calculate percentage returns\n",
        "    data = data.dropna()  # Remove missing values\n",
        "    data = data.reset_index()\n",
        "    data.columns = ['ds', 'y', 'Volume', 'Returns']\n",
        "    data['unique_id'] = ticker\n",
        "    return data\n",
        "\n",
        "def run_experiment(stock_data, val_size, test_size, freq, ticker, horizon, epochs):\n",
        "    models = [\n",
        "        iTransformer(h=horizon, input_size=5*horizon, n_series=1, max_steps=epochs, early_stop_patience_steps=5),\n",
        "        TSMixer(h=horizon, input_size=5*horizon, n_series=1, max_steps=epochs, early_stop_patience_steps=5),\n",
        "        NHITS(h=horizon, input_size=5*horizon, max_steps=epochs, early_stop_patience_steps=5),\n",
        "        PatchTST(h=horizon, input_size=5*horizon, max_steps=epochs, early_stop_patience_steps=5)\n",
        "    ]\n",
        "\n",
        "    # Save the mean and std dev of the columns\n",
        "    mean = stock_data[['y', 'Volume', 'Returns']].mean()\n",
        "    std = stock_data[['y', 'Volume', 'Returns']].std()\n",
        "\n",
        "    # Normalize the input data\n",
        "    stock_data[['y', 'Volume', 'Returns']] = (stock_data[['y', 'Volume', 'Returns']] - mean) / std\n",
        "\n",
        "    nf = NeuralForecast(models=models, freq=freq)\n",
        "    nf_preds = nf.cross_validation(df=stock_data, val_size=val_size, test_size=test_size, n_windows=None)\n",
        "    nf_preds = nf_preds.reset_index()\n",
        "    evaluation = evaluate(df=nf_preds, metrics=[mae, mse], models=['iTransformer', 'TSMixer', 'NHITS', 'PatchTST'])\n",
        "    evaluation.to_csv(f'{ticker}_results_horizon_{horizon}_epochs_{epochs}.csv', index=False, header=True)\n",
        "    return evaluation, nf_preds\n",
        "\n",
        "tickers = ['SPY']\n",
        "start_date = '2010-01-01'\n",
        "end_date = '2023-04-30'\n",
        "horizon = 7\n",
        "epochs = 2000\n",
        "\n",
        "dataframes = []\n",
        "predictions_dfs = []\n",
        "for ticker in tickers:\n",
        "    stock_data = load_stock_data(ticker, start_date, end_date)\n",
        "    val_size = 365\n",
        "    test_size = 7\n",
        "    freq = 'D'\n",
        "\n",
        "    evaluation, nf_preds = run_experiment(stock_data, val_size, test_size, freq, ticker, horizon, epochs)\n",
        "    evaluation['ticker'] = ticker\n",
        "    dataframes.append(evaluation)\n",
        "    predictions_dfs.append(nf_preds.copy())\n",
        "\n",
        "\n",
        "full_df = pd.concat(dataframes, ignore_index=True)\n",
        "full_df = full_df.drop(['unique_id'], axis=1)\n",
        "\n",
        "model_names = ['iTransformer', 'TSMixer', 'NHITS', 'PatchTST']\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
        "bar_width = 0.35\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, ticker in enumerate(tickers):\n",
        "    df_subset = full_df[(full_df['ticker'] == ticker) & (full_df['metric'] == 'mae')]\n",
        "    mae_vals = df_subset[model_names].values.flatten()\n",
        "    df_subset = full_df[(full_df['ticker'] == ticker) & (full_df['metric'] == 'mse')]\n",
        "    mse_vals = df_subset[model_names].values.flatten()\n",
        "    indices = np.arange(len(model_names))\n",
        "\n",
        "    bars_mae = axs[i].bar(indices - bar_width / 2, mae_vals, bar_width, color='skyblue', label='MAE')\n",
        "    bars_mse = axs[i].bar(indices + bar_width / 2, mse_vals, bar_width, color='orange', label='MSE')\n",
        "\n",
        "    for bars in [bars_mae, bars_mse]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            axs[i].annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                            xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
        "\n",
        "    axs[i].set_xticks(indices)\n",
        "    axs[i].set_xticklabels(model_names, rotation=45)\n",
        "    axs[i].set_title(ticker)\n",
        "    axs[i].legend(loc='best')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "for i, ticker in enumerate(tickers):\n",
        "    nf_preds = predictions_dfs[i]\n",
        "    stock_data = load_stock_data(ticker, start_date, end_date)\n",
        "\n",
        "    # Get the mean and standard deviation of the target variable (y)\n",
        "    y_mean = stock_data['y'].mean()\n",
        "    y_std = stock_data['y'].std()\n",
        "\n",
        "    # Rescale the predicted prices\n",
        "    rescaled_predictions_df = nf_preds.copy()\n",
        "    rescaled_predictions_df[['iTransformer', 'TSMixer', 'NHITS', 'PatchTST', 'y']] = \\\n",
        "        (nf_preds[['iTransformer', 'TSMixer', 'NHITS', 'PatchTST', 'y']] * y_std) + y_mean\n",
        "    # Save the rescaled predictions to a CSV file\n",
        "    now = datetime.now()\n",
        "    dt_string = now.strftime(\"%d_%m_%Y %H:%M\")\n",
        "    csv_file = f'predictions/{ticker}_rescaled_predictions_horizon_{horizon}_epochs_{epochs}_{dt_string}.csv'\n",
        "    rescaled_predictions_df.to_csv(csv_file, index=False, header=True)\n",
        "\n",
        "    for model_name in model_names:\n",
        "        plt.figure(figsize=(16, 8))\n",
        "        plt.plot(stock_data['ds'], stock_data['y'], label='Actual Price', linewidth=3, color='blue')\n",
        "        plt.plot(rescaled_predictions_df['ds'], rescaled_predictions_df[model_name],\n",
        "                 label=model_name, linewidth=1, color='red')\n",
        "\n",
        "        plt.xlabel('Date', fontsize=14)\n",
        "        plt.ylabel('Price', fontsize=14)\n",
        "        plt.title(f'{ticker} Stock Price Prediction - {model_name}', fontsize=16)\n",
        "        plt.grid(axis='y')\n",
        "        plt.legend(loc='upper left', fontsize=12)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ewBA-1GAId5e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}